{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploy a model to a Local endpoint, using Azure Machine Learning Python SDK v2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1685486329865
        }
      },
      "outputs": [],
      "source": [
        "# ! pip install azure-ai-ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1687967218052
        }
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        "    CodeConfiguration,\n",
        "    OnlineRequestSettings\n",
        ")\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.identity import DefaultAzureCredential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1687967221645
        }
      },
      "outputs": [],
      "source": [
        "# enter details of your AML workspace\n",
        "subscription_id = \"<SUBSCRIPTION_ID>\"\n",
        "resource_group = \"<RESOURCE_GROUP>\"\n",
        "workspace = \"<AML_WORKSPACE_NAME>\"\n",
        "\n",
        "# get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687967914375
        }
      },
      "outputs": [],
      "source": [
        "online_endpoint_name = \"padchest-optimized-ipex-ov-sdk-v2-local\"\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name = online_endpoint_name, \n",
        "    description=\"local deployment: padchest-optimized-ipex-ov-sdk-v2-local\",\n",
        "    auth_mode=\"key\"\n",
        ")\n",
        "\n",
        "poller = ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)\n",
        "# poller.wait()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687967941258
        }
      },
      "outputs": [],
      "source": [
        "# Configure a model\n",
        "\n",
        "\n",
        "folder_model_path=\"./outputs/az-register-models\"\n",
        "\n",
        "file_model = Model(\n",
        "    path=folder_model_path,\n",
        "    type=AssetTypes.CUSTOM_MODEL,\n",
        "    name=\"This is local: padchest-optimized-ipex-ov-sdk-v2-local\",\n",
        "    version=\"1\",\n",
        "    description=\"SDKv2-az-register-models with PT, ONNX and OV models of padchest\"\n",
        ")\n",
        "ml_client.models.create_or_update(file_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1687970910761
        }
      },
      "outputs": [],
      "source": [
        "# Configure an environment\n",
        "\n",
        "env = Environment(\n",
        "    conda_file=\"conda_dep_opti.yml\",\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        "    )\n",
        "\n",
        "\n",
        "# configure an inference configuration with a scoring script\n",
        "code_config = CodeConfiguration(\n",
        "        code=\"padchest_score_code\",\n",
        "        scoring_script=\"score_opti.py\"\n",
        "    )   "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Deployment\n",
        "See VM SKUs that are supported for Azure Machine Learning managed online endpoints [here](https://learn.microsoft.com/en-us/azure/machine-learning/reference-managed-online-endpoints-vm-sku-list?view=azureml-api-2)\n",
        "\n",
        "- For LOCAL deployments, pass `local=True` parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687970919047
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "req_settings = OnlineRequestSettings(request_timeout_ms=90000)\n",
        "\n",
        "# Define a deployment\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=file_model,\n",
        "    environment=env,\n",
        "    code_configuration=code_config,\n",
        "    instance_type=\"Standard_FX4mds\", #Standard_FX12mds, #Standard_FX24mds \n",
        "    instance_count=1,\n",
        "    request_settings=req_settings\n",
        ")\n",
        "\n",
        "# create the deployment:\n",
        "poller = ml_client.begin_create_or_update(blue_deployment, local=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687971166179
        }
      },
      "outputs": [],
      "source": [
        "# blue deployment takes 100% traffic\n",
        "endpoint.traffic = {\"blue\": 100}\n",
        "ml_client.begin_create_or_update(endpoint, local=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1685993900732
        }
      },
      "outputs": [],
      "source": [
        "deployment_logs = ml_client.online_deployments.get_logs(\n",
        "    name=\"blue\", endpoint_name=online_endpoint_name, lines=50, local=True\n",
        ")\n",
        "deployment_logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687971197115
        }
      },
      "outputs": [],
      "source": [
        "# Get the details for online endpoint\n",
        "deployed_endpoint = ml_client.online_endpoints.get(name=online_endpoint_name, local=True)\n",
        "\n",
        "# existing traffic details\n",
        "print(deployed_endpoint.traffic)\n",
        "\n",
        "# Get the scoring URI\n",
        "print(deployed_endpoint.scoring_uri)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687968719552
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# visualize image\n",
        "\n",
        "import pydicom\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "# Visualize converted DICOM file from the corresponding PNG file\n",
        "test_file = \"./sample_dicom.dcm\"\n",
        "dcm = pydicom.read_file(test_file)\n",
        "print(dcm)\n",
        "plt.imshow(dcm.pixel_array, cmap=plt.cm.bone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687971236518
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "test_file = \"./sample_dicom.dcm\"\n",
        "files = {'image': open(test_file, 'rb').read()}\n",
        "\n",
        "# resp = requests.post(scoring_uri, input_data, headers=headers)\n",
        "scoring_uri = endpoint_deployed.scoring_uri\n",
        "\n",
        "# Send the DICOM as a raw HTTP request and obtain results from endpoint.\n",
        "response = requests.post(scoring_uri, files=files)\n",
        "print(\"output:\", response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "gather": {
          "logged": 1687974788821
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock PyTorch Metrics:\n",
            "\tFramework Version:\tPyTorch: 1.13.1+cpu\n",
            "\tTop Labels:\t['Pneumonia', 'Infiltration', 'Effusion']\n",
            "\tTop Probabilities:\t[49.63, 32.22, 3.29]\n",
            "\tAvg Latency:\t0.0506 sec\n",
            "\tFPS:\t19.76\n",
            "PyTorch Graph Mode Metrics:\n",
            "\tFramework Version:\tPyTorch: 1.13.1+cpu\n",
            "\tTop Labels:\t['Pneumonia', 'Infiltration', 'Effusion']\n",
            "\tTop Probabilities:\t[49.63, 32.22, 3.29]\n",
            "\tAvg Latency:\t0.0429 sec\n",
            "\tFPS:\t23.32\n",
            "\n",
            "IPEX Eager Metrics:\n",
            "\tFramework Version:\tIPEX: 1.13.100\n",
            "\tTop Labels:\t['Pneumonia', 'Infiltration', 'Effusion']\n",
            "\tTop Probabilities:\t[49.63, 32.22, 3.29]\n",
            "\tAvg Latency:\t0.0585 sec\n",
            "\tFPS:\t17.09\n",
            "\n",
            "IPEX Graph Mode Metrics:\n",
            "\tFramework Version:\tIPEX: 1.13.100\n",
            "\tTop Labels:\t['Pneumonia', 'Infiltration', 'Effusion']\n",
            "\tTop Probabilities:\t[49.63, 32.22, 3.29]\n",
            "\tAvg Latency:\t0.0273 sec\n",
            "\tFPS:\t36.69\n",
            "\n",
            "OpenVINO Metrics:\n",
            "\tFramework Version:\tOpenVINO: 2023.0.0-10926-b4452d56304-releases/2023/0\n",
            "\tTop Labels:\t['Pneumonia', 'Infiltration', 'Effusion']\n",
            "\tTop Probabilities:\t[49.63, 32.22, 3.29]\n",
            "\tAvg Latency:\t0.0208 sec\n",
            "\tFPS:\t48.10\n",
            "\n",
            "Speedup with IPEX: 1.86x\n",
            "\n",
            "Speedup with OV: 2.43x\n",
            "\n",
            "Speedup with stock graph mode: 1.18x\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "output_dict = json.loads(response.content)\n",
        "\n",
        "pt_metrics = output_dict['pt_summary']\n",
        "pt_graph_metrics = output_dict['pt_graph_summary']\n",
        "ipex_metrics = output_dict['ipex_eager_summary']\n",
        "ipex_graph_metrics = output_dict['ipex_graph_summary']\n",
        "ov_metrics = output_dict['ov_summary']\n",
        "\n",
        "print(f\"Stock PyTorch Metrics:\")\n",
        "print(f\"\\tFramework Version:\\t{pt_metrics['fwk_version']}\")\n",
        "print(f\"\\tTop Labels:\\t{pt_metrics['pt_result']['top_labels']}\")\n",
        "print(f\"\\tTop Probabilities:\\t{pt_metrics['pt_result']['top_probabilities']}\")\n",
        "print(f\"\\tAvg Latency:\\t{pt_metrics['avg_latency']:.4f} sec\")\n",
        "print(f\"\\tFPS:\\t{pt_metrics['fps']:.2f}\")\n",
        "\n",
        "print(f\"PyTorch Graph Mode Metrics:\")\n",
        "print(f\"\\tFramework Version:\\t{pt_graph_metrics['fwk_version']}\")\n",
        "print(f\"\\tTop Labels:\\t{pt_graph_metrics['pt_graph_result']['top_labels']}\")\n",
        "print(f\"\\tTop Probabilities:\\t{pt_graph_metrics['pt_graph_result']['top_probabilities']}\")\n",
        "print(f\"\\tAvg Latency:\\t{pt_graph_metrics['avg_latency']:.4f} sec\")\n",
        "print(f\"\\tFPS:\\t{pt_graph_metrics['fps']:.2f}\")\n",
        "\n",
        "print(f\"\\nIPEX Eager Metrics:\")\n",
        "print(f\"\\tFramework Version:\\t{ipex_metrics['fwk_version']}\")\n",
        "print(f\"\\tTop Labels:\\t{ipex_metrics['ipex_result']['top_labels']}\")\n",
        "print(f\"\\tTop Probabilities:\\t{ipex_metrics['ipex_result']['top_probabilities']}\")\n",
        "print(f\"\\tAvg Latency:\\t{ipex_metrics['avg_latency']:.4f} sec\")\n",
        "print(f\"\\tFPS:\\t{ipex_metrics['fps']:.2f}\")\n",
        "\n",
        "print(f\"\\nIPEX Graph Mode Metrics:\")\n",
        "print(f\"\\tFramework Version:\\t{ipex_graph_metrics['fwk_version']}\")\n",
        "print(f\"\\tTop Labels:\\t{ipex_graph_metrics['ipex_graph_result']['top_labels']}\")\n",
        "print(f\"\\tTop Probabilities:\\t{ipex_graph_metrics['ipex_graph_result']['top_probabilities']}\")\n",
        "print(f\"\\tAvg Latency:\\t{ipex_graph_metrics['avg_latency']:.4f} sec\")\n",
        "print(f\"\\tFPS:\\t{ipex_graph_metrics['fps']:.2f}\")\n",
        "\n",
        "print(f\"\\nOpenVINO Metrics:\")\n",
        "print(f\"\\tFramework Version:\\t{ov_metrics['fwk_version']}\")\n",
        "print(f\"\\tTop Labels:\\t{ov_metrics['ov_result']['top_labels']}\")\n",
        "print(f\"\\tTop Probabilities:\\t{ov_metrics['ov_result']['top_probabilities']}\")\n",
        "print(f\"\\tAvg Latency:\\t{ov_metrics['avg_latency']:.4f} sec\")\n",
        "print(f\"\\tFPS:\\t{ov_metrics['fps']:.2f}\")\n",
        "\n",
        "\n",
        "# Calculate the FPS speedup with IPEX compared to PyTorch\n",
        "ipex_fps_speedup = ipex_graph_metrics['fps'] / pt_metrics['fps']\n",
        "print(f\"\\nSpeedup with IPEX: {ipex_fps_speedup:.2f}x\")\n",
        "\n",
        "# Calculate the FPS speedup with OpenVINO compared to PyTorch\n",
        "ov_fps_speedup = ov_metrics['fps'] / pt_metrics['fps']\n",
        "print(f\"\\nSpeedup with OV: {ov_fps_speedup:.2f}x\")\n",
        "\n",
        "# Calculate the FPS speedup with Stock Graph Mode compared to PyTorch\n",
        "ov_fps_speedup = pt_graph_metrics['fps'] / pt_metrics['fps']\n",
        "print(f\"\\nSpeedup with stock graph mode: {ov_fps_speedup:.2f}x\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687974811038
        }
      },
      "outputs": [],
      "source": [
        "#Print System info\n",
        "lscpu_out=output_dict['system_info']['lscpu_out'].encode().decode('unicode_escape')\n",
        "print(f\"\\nSystem Info:\\n{lscpu_out}\")\n",
        "\n",
        "mem_out_gb=output_dict['system_info']['mem_out_gb'].encode().decode('unicode_escape')\n",
        "print(f\"\\nSystem Memory Info (GB):\\n{mem_out_gb}\")\n",
        "\n",
        "os_out=output_dict['system_info']['os'].encode().decode('unicode_escape')\n",
        "print(f\"\\nSystem OS:\\n{os_out}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Delete endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".."
          ]
        }
      ],
      "source": [
        "#ml_client.online_endpoints.begin_delete(name=online_endpoint_name, local=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

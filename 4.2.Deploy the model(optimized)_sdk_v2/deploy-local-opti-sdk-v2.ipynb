{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploy a model to a Local endpoint, using Azure Machine Learning Python SDK v2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "! pip install azure-ai-ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        "    CodeConfiguration,\n",
        ")\n",
        "from azure.identity import DefaultAzureCredential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# enter details of your AML workspace\n",
        "subscription_id = \"<SUBSCRIPTION_ID>\"\n",
        "resource_group = \"<RESOURCE_GROUP>\"\n",
        "workspace_name = \"<AML_WORKSPACE_NAME>\"\n",
        "\n",
        "# authenticate\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=subscription_id,\n",
        "    resource_group_name=resource_group,\n",
        "    workspace_name=workspace_name,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Configure an environment\n",
        "\n",
        "env = Environment(\n",
        "    conda_file=\"conda_dep_opti.yml\",\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        "    )\n",
        "\n",
        "# configure an inference configuration with a code folder and scoring script\n",
        "code_config = CodeConfiguration(\n",
        "        code=\"padchest_score_code\",\n",
        "        scoring_script=\"score_opti.py\"\n",
        "    ) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# configure a model\n",
        "model_path=\"../outputs/az-register-models\"\n",
        "\n",
        "model = Model(\n",
        "    path=model_path,\n",
        "    type=\"custom_model\",\n",
        "    name=\"padchest-pt-onnx-ov\",\n",
        "    version=\"1\",\n",
        "    description=\"A folder az-register-models with PT, ONNX and OV models of padchest\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Updating local endpoint (padchest-pt-ipex-ov-local-sdk-v2) .Done (0m 5s)\n"
          ]
        }
      ],
      "source": [
        "endpoint_name = \"padchest-pt-ipex-ov-local-sdk-v2\"\n",
        "# Define and setup an endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name = endpoint_name, \n",
        "    description=\"this is local: padchest-pt-ipex-ov-local-sdk-v2\",\n",
        "    auth_mode=\"key\"\n",
        ")\n",
        "\n",
        "# create an LOCAL endpoint\n",
        "poller = ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)\n",
        "#poller.wait()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Deployment\n",
        "See VM SKUs that are supported for Azure Machine Learning managed online endpoints [here](https://learn.microsoft.com/en-us/azure/machine-learning/reference-managed-online-endpoints-vm-sku-list?view=azureml-api-2)\n",
        "\n",
        "- For LOCAL deployments, pass `local=True` parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Updating local deployment (padchest-pt-ipex-ov-local-sdk-v2 / blue) .\n",
            "Building Docker image from Dockerfile\n",
            "Step 1/6 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\n",
            " ---> a663ea825a6c\n",
            "Step 2/6 : RUN mkdir -p /var/azureml-app/\n",
            " ---> Using cache\n",
            " ---> 11cb60119f42\n",
            "Step 3/6 : WORKDIR /var/azureml-app/\n",
            " ---> Using cache\n",
            " ---> 880258a5c0d4\n",
            "Step 4/6 : COPY conda.yml /var/azureml-app/\n",
            " ---> Using cache\n",
            " ---> a6df009a097b\n",
            "Step 5/6 : RUN conda env create -n inf-conda-env --file conda.yml\n",
            " ---> Using cache\n",
            " ---> b215e53bc271\n",
            "Step 6/6 : CMD [\"conda\", \"run\", \"--no-capture-output\", \"-n\", \"inf-conda-env\", \"runsvdir\", \"/var/runit\"]\n",
            " ---> Using cache\n",
            " ---> 957b35d935b2\n",
            "Successfully built 957b35d935b2\n",
            "Successfully tagged padchest-pt-ipex-ov-local-sdk-v2:blue\n",
            "\n",
            "Starting up endpoint...Done (0m 20s)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ManagedOnlineDeployment({'private_network_connection': None, 'provisioning_state': 'Succeeded', 'endpoint_name': 'padchest-pt-ipex-ov-local-sdk-v2', 'type': 'Managed', 'name': 'blue', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/ravi-nuance/code/Users/ravi.panchumarthy/01.PadChest/Medical-Imaging-AI-RSNA-2021-Demo/4.2.Deploy the model(optimized)_sdk_v2'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f1d640b7b50>, 'model': Model({'job_name': None, 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'padchest-pt-onnx-ov', 'description': 'A folder az-register-models with PT, ONNX and OV models of padchest', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/ravi-nuance/code/Users/ravi.panchumarthy/01.PadChest/Medical-Imaging-AI-RSNA-2021-Demo/4.2.Deploy the model(optimized)_sdk_v2'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f1d4def20a0>, 'version': '1', 'latest_version': None, 'path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ravi-nuance/code/Users/ravi.panchumarthy/01.PadChest/Medical-Imaging-AI-RSNA-2021-Demo/outputs/az-register-models', 'datastore': None, 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model'}), 'code_configuration': {'code': '.'}, 'environment': Environment({'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'CliV2AnonymousEnvironment', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/ravi-nuance/code/Users/ravi.panchumarthy/01.PadChest/Medical-Imaging-AI-RSNA-2021-Demo/4.2.Deploy the model(optimized)_sdk_v2'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f1d4d67f430>, 'version': 'e3edde130294af730135edf470ee8cee', 'latest_version': None, 'conda_file': {'channels': ['anaconda', 'defaults'], 'dependencies': ['python=3.9', {'pip': ['azureml-defaults', 'azure-ml-api-sdk', 'torchxrayvision', 'pydicom', 'openvino-dev', 'torch==1.13.1+cpu', 'torchvision==0.14.1+cpu', 'intel_extension_for_pytorch==1.13.100', '--index-url https://pypi.org/simple/', '--extra-index-url https://download.pytorch.org/whl/cpu']}]}, 'image': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest', 'build': None, 'inference_config': None, 'os_type': None, 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': 'channels:\\n- anaconda\\n- defaults\\ndependencies:\\n- python=3.9\\n- pip:\\n  - azureml-defaults\\n  - azure-ml-api-sdk\\n  - torchxrayvision\\n  - pydicom\\n  - openvino-dev\\n  - torch==1.13.1+cpu\\n  - torchvision==0.14.1+cpu\\n  - intel_extension_for_pytorch==1.13.100\\n  - --index-url https://pypi.org/simple/\\n  - --extra-index-url https://download.pytorch.org/whl/cpu\\n'}), 'environment_variables': {}, 'app_insights_enabled': False, 'scale_settings': None, 'request_settings': None, 'liveness_probe': None, 'readiness_probe': None, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'local', 'data_collector': None, 'egress_public_network_access': None})"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# define a deployment\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=endpoint_name,\n",
        "    model=model,\n",
        "    environment=env,\n",
        "    code_configuration=code_config,\n",
        "    instance_type=\"Standard_F2s_v2\",\n",
        "    instance_count=1,\n",
        ")\n",
        "\n",
        "# create the deployment:\n",
        "ml_client.begin_create_or_update(blue_deployment, local=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Updating local endpoint (padchest-pt-ipex-ov-local-sdk-v2) .Done (0m 5s)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ManagedOnlineEndpoint({'public_network_access': None, 'provisioning_state': 'Succeeded', 'scoring_uri': 'http://localhost:32815/score', 'openapi_uri': None, 'name': 'padchest-pt-ipex-ov-local-sdk-v2', 'description': 'this is local: padchest-pt-ipex-ov-local-sdk-v2', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/ravi-nuance/code/Users/ravi.panchumarthy/01.PadChest/Medical-Imaging-AI-RSNA-2021-Demo/4.2.Deploy the model(optimized)_sdk_v2'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f1d4d689fa0>, 'auth_mode': 'key', 'location': 'local', 'identity': None, 'traffic': {'blue': 100}, 'mirror_traffic': {}, 'kind': None})"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# blue deployment takes 100% traffic\n",
        "endpoint.traffic = {\"blue\": 100}\n",
        "ml_client.begin_create_or_update(endpoint, local=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ManagedOnlineEndpoint({'public_network_access': None, 'provisioning_state': 'Succeeded', 'scoring_uri': 'http://localhost:32815/score', 'openapi_uri': None, 'name': 'padchest-pt-ipex-ov-local-sdk-v2', 'description': 'this is local: padchest-pt-ipex-ov-local-sdk-v2', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/ravi-nuance/code/Users/ravi.panchumarthy/01.PadChest/Medical-Imaging-AI-RSNA-2021-Demo/4.2.Deploy the model(optimized)_sdk_v2'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f1d4d689bb0>, 'auth_mode': 'key', 'location': 'local', 'identity': None, 'traffic': {'blue': 100}, 'mirror_traffic': {}, 'kind': None})"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.online_endpoints.get(name=endpoint_name, local=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2023-05-25T07:04:12,155223459+00:00 - rsyslog/run \\r\\n2023-05-25T07:04:12,157592978+00:00 - nginx/run \\r\\n2023-05-25T07:04:12,159750994+00:00 - gunicorn/run \\r\\n2023-05-25T07:04:12,161339807+00:00 | gunicorn/run | \\r\\n2023-05-25T07:04:12,162615217+00:00 | gunicorn/run | ###############################################\\r\\n2023-05-25T07:04:12,164068428+00:00 | gunicorn/run | AzureML Container Runtime Information\\r\\n2023-05-25T07:04:12,165608940+00:00 | gunicorn/run | ###############################################\\r\\n2023-05-25T07:04:12,170957082+00:00 | gunicorn/run | \\r\\n2023-05-25T07:04:12,611426621+00:00 | gunicorn/run | \\r\\n2023-05-25T07:04:12,614365144+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20230524.v1\\r\\n2023-05-25T07:04:12,615767155+00:00 | gunicorn/run | \\r\\n2023-05-25T07:04:12,617094166+00:00 | gunicorn/run | \\r\\n2023-05-25T07:04:12,618452576+00:00 | gunicorn/run | PATH environment variable: /opt/miniconda/envs/inf-conda-env/bin:/opt/miniconda/condabin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\\r\\n2023-05-25T07:04:12,619752886+00:00 | gunicorn/run | PYTHONPATH environment variable: \\r\\n2023-05-25T07:04:12,621008596+00:00 | gunicorn/run | \\r\\n2023-05-25T07:04:13,016465584+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\\r\\n\\r\\n# conda environments:\\r\\n#\\r\\nbase                     /opt/miniconda\\r\\ninf-conda-env         *  /opt/miniconda/envs/inf-conda-env\\r\\n\\r\\n2023-05-25T07:04:13,820799565+00:00 | gunicorn/run | \\r\\n2023-05-25T07:04:13,822633979+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\\r\\n\\r\\nadal==1.2.7\\r\\naddict==2.4.0\\r\\nargcomplete==2.1.2\\r\\nattrs==23.1.0\\r\\nazure-common==1.1.28\\r\\nazure-core==1.26.4\\r\\nazure-graphrbac==0.61.1\\r\\nazure-identity==1.13.0\\r\\nazure-mgmt-authorization==3.0.0\\r\\nazure-mgmt-containerregistry==10.1.0\\r\\nazure-mgmt-core==1.4.0\\r\\nazure-mgmt-keyvault==10.2.2\\r\\nazure-mgmt-resource==22.0.0\\r\\nazure-mgmt-storage==21.0.0\\r\\nazure-ml-api-sdk==0.1.0a11\\r\\nazureml-core==1.51.0\\r\\nazureml-dataprep==4.10.7\\r\\nazureml-dataprep-native==38.0.0\\r\\nazureml-dataprep-rslex==2.17.11\\r\\nazureml-dataset-runtime==1.51.0\\r\\nazureml-defaults==1.51.0\\r\\nazureml-inference-server-http==0.8.4\\r\\nbackports.tempfile==1.0\\r\\nbackports.weakref==1.0.post1\\r\\nbcrypt==4.0.1\\r\\ncachetools==5.3.0\\r\\ncertifi @ file:///croot/certifi_1671487769961/work/certifi\\r\\ncffi==1.15.1\\r\\ncharset-normalizer==3.1.0\\r\\nclick==8.1.3\\r\\ncloudpickle==2.2.1\\r\\ncontextlib2==21.6.0\\r\\ncryptography==40.0.2\\r\\ndefusedxml==0.7.1\\r\\ndistro==1.8.0\\r\\ndocker==6.1.2\\r\\ndotnetcore2==3.1.23\\r\\nFlask==2.2.5\\r\\nFlask-Cors==3.0.10\\r\\nfusepy==3.0.1\\r\\ngoogle-api-core==2.11.0\\r\\ngoogle-auth==2.18.1\\r\\ngoogleapis-common-protos==1.59.0\\r\\ngunicorn==20.1.0\\r\\nhumanfriendly==10.0\\r\\nidna==3.4\\r\\nimageio==2.29.0\\r\\nimportlib-metadata==6.6.0\\r\\ninference-schema==1.5.1\\r\\nintel-extension-for-pytorch==1.13.100\\r\\nisodate==0.6.1\\r\\nitsdangerous==2.1.2\\r\\njeepney==0.8.0\\r\\nJinja2==3.1.2\\r\\njmespath==1.0.1\\r\\njsonpickle==3.0.1\\r\\njsonschema==4.17.3\\r\\njstyleson==0.0.2\\r\\nknack==0.10.1\\r\\nlazy_loader==0.2\\r\\nliac-arff==2.5.0\\r\\nMarkupSafe==2.1.2\\r\\nmsal==1.22.0\\r\\nmsal-extensions==1.0.0\\r\\nmsrest==0.7.1\\r\\nmsrestazure==0.6.4\\r\\nndg-httpsclient==0.5.1\\r\\nnetworkx==2.8.8\\r\\nnumpy==1.23.4\\r\\noauthlib==3.2.2\\r\\nopencensus==0.11.2\\r\\nopencensus-context==0.1.3\\r\\nopencensus-ext-azure==1.1.9\\r\\nopencv-python==4.7.0.72\\r\\nopenvino==2022.3.0\\r\\nopenvino-dev==2022.3.0\\r\\nopenvino-telemetry==2022.3.0\\r\\npackaging==23.0\\r\\npandas==1.3.5\\r\\nparamiko==3.1.0\\r\\npathspec==0.11.1\\r\\nPillow==9.5.0\\r\\npkginfo==1.9.6\\r\\nportalocker==2.7.0\\r\\nprotobuf==4.23.1\\r\\npsutil==5.9.5\\r\\npyarrow==9.0.0\\r\\npyasn1==0.5.0\\r\\npyasn1-modules==0.3.0\\r\\npycparser==2.21\\r\\npydantic==1.10.8\\r\\npydicom==2.3.1\\r\\nPygments==2.15.1\\r\\nPyJWT==2.7.0\\r\\nPyNaCl==1.5.0\\r\\npyOpenSSL==23.1.1\\r\\npyrsistent==0.19.3\\r\\nPySocks==1.7.1\\r\\npython-dateutil==2.8.2\\r\\npytz==2023.3\\r\\nPyWavelets==1.4.1\\r\\nPyYAML==6.0\\r\\nrequests==2.31.0\\r\\nrequests-oauthlib==1.3.1\\r\\nrsa==4.9\\r\\nscikit-image==0.20.0\\r\\nscipy==1.9.1\\r\\nSecretStorage==3.3.3\\r\\nsix==1.16.0\\r\\ntabulate==0.9.0\\r\\ntexttable==1.6.7\\r\\ntifffile==2023.4.12\\r\\ntorch==1.13.1+cpu\\r\\ntorchvision==0.14.1+cpu\\r\\ntorchxrayvision==1.1.1\\r\\ntqdm==4.65.0\\r\\ntyping_extensions==4.6.1\\r\\nurllib3==1.26.16\\r\\nwebsocket-client==1.5.2\\r\\nWerkzeug==2.3.4\\r\\nwrapt==1.12.1\\r\\nzipp==3.15.0\\r\\n\\r\\n2023-05-25T07:04:14,250032616+00:00 | gunicorn/run | \\r\\n2023-05-25T07:04:14,251576428+00:00 | gunicorn/run | ###############################################\\r\\n2023-05-25T07:04:14,253124040+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\\r\\n2023-05-25T07:04:14,254409250+00:00 | gunicorn/run | ###############################################\\r\\n2023-05-25T07:04:14,255817961+00:00 | gunicorn/run | \\r\\n2023-05-25T07:04:15,182629798+00:00 | gunicorn/run | \\r\\n2023-05-25T07:04:15,184269811+00:00 | gunicorn/run | ###############################################\\r\\n2023-05-25T07:04:15,185873024+00:00 | gunicorn/run | AzureML Inference Server\\r\\n2023-05-25T07:04:15,187458036+00:00 | gunicorn/run | ###############################################\\r\\n2023-05-25T07:04:15,189003248+00:00 | gunicorn/run | \\r\\n2023-05-25T07:04:16,086082753+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\\r\\n2023-05-25 07:04:16,223 I [24] azmlinfsrv - Loaded logging config from /opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/logging.json\\r\\n\\r\\nAzure ML Inferencing HTTP server v0.8.4\\r\\n\\r\\n\\r\\nServer Settings\\r\\n---------------\\r\\nEntry Script Name: /var/azureml-app/4.2.Deploy the model(optimized)_sdk_v2/score_opt_local.py\\r\\nModel Directory: /var/azureml-app/azureml-models//padchest-pt-onnx-ov/None\\r\\nConfig File: None\\r\\nWorker Count: 1\\r\\nWorker Timeout (seconds): 300\\r\\nServer Port: 31311\\r\\nHealth Port: 31311\\r\\nApplication Insights Enabled: false\\r\\nApplication Insights Key: None\\r\\nInferencing HTTP server version: azmlinfsrv/0.8.4\\r\\nCORS for the specified origins: None\\r\\nCreate dedicated endpoint for health: None\\r\\n\\r\\n\\r\\nServer Routes\\r\\n---------------\\r\\nLiveness Probe: GET   127.0.0.1:31311/\\r\\nScore:          POST  127.0.0.1:31311/score\\r\\n\\r\\n2023-05-25 07:04:16,379 I [24] gunicorn.error - Starting gunicorn 20.1.0\\r\\n2023-05-25 07:04:16,380 I [24] gunicorn.error - Listening at: http://0.0.0.0:31311 (24)\\r\\n2023-05-25 07:04:16,380 I [24] gunicorn.error - Using worker: sync\\r\\n2023-05-25 07:04:16,382 I [86] gunicorn.error - Booting worker with pid: 86\\r\\n/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/config.py:51: FutureWarning: aliases are no longer used by BaseSettings to define which environment variables to read. Instead use the \"env\" field setting. See https://pydantic-docs.helpmanual.io/usage/settings/#environment-variable-names\\r\\n  class AMLInferenceServerConfig(pydantic.BaseSettings):\\r\\n2023-05-25 07:04:16,686 I [86] azmlinfsrv - AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\\r\\nInitializing logger\\r\\n2023-05-25 07:04:16,688 I [86] azmlinfsrv - Starting up app insights client\\r\\n2023-05-25 07:04:18,948 I [86] azmlinfsrv.user_script - Found user script at /var/azureml-app/4.2.Deploy the model(optimized)_sdk_v2/score_opt_local.py\\r\\n2023-05-25 07:04:18,948 I [86] azmlinfsrv.user_script - run() is decorated with @rawhttp. Server will invoke it with the flask request object.\\r\\n2023-05-25 07:04:18,948 I [86] azmlinfsrv.user_script - Invoking user\\'s init function\\r\\n2023-05-25 07:04:18,948 I [86] azmlinfsrv.print - \\r\\n\\r\\n\\r\\nDEBUGINNNNN\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n2023-05-25 07:04:18,948 I [86] azmlinfsrv.print - Contents of directory \\'/var/azureml-app/azureml-models\\':\\r\\n2023-05-25 07:04:18,948 I [86] azmlinfsrv.print - Directory: /var/azureml-app/azureml-models/padchest-pt-onnx-ov\\r\\n2023-05-25 07:04:18,949 I [86] azmlinfsrv.print - Directory: /var/azureml-app/azureml-models/padchest-pt-onnx-ov/None\\r\\n2023-05-25 07:04:18,949 I [86] azmlinfsrv.print - Directory: /var/azureml-app/azureml-models/padchest-pt-onnx-ov/None:z\\r\\n2023-05-25 07:04:18,961 I [86] azmlinfsrv.print - File: /var/azureml-app/azureml-models/padchest-pt-onnx-ov/None/.amlignore\\r\\n2023-05-25 07:04:18,961 I [86] azmlinfsrv.print - File: /var/azureml-app/azureml-models/padchest-pt-onnx-ov/None/.amlignore.amltmp\\r\\n2023-05-25 07:04:18,961 I [86] azmlinfsrv.print - File: /var/azureml-app/azureml-models/padchest-pt-onnx-ov/None/class_names.txt\\r\\n2023-05-25 07:04:18,961 I [86] azmlinfsrv.print - File: /var/azureml-app/azureml-models/padchest-pt-onnx-ov/None/pc-densenet-densenet-best.onnx\\r\\n2023-05-25 07:04:18,961 I [86] azmlinfsrv.print - File: /var/azureml-app/azureml-models/padchest-pt-onnx-ov/None/pc-densenet-densenet-best.pt\\r\\n2023-05-25 07:04:18,961 I [86] azmlinfsrv.print - File: /var/azureml-app/azureml-models/padchest-pt-onnx-ov/None/pc-densenet-densenet-metrics.pkl\\r\\n2023-05-25 07:04:18,961 I [86] azmlinfsrv.print - Directory: /var/azureml-app/azureml-models/padchest-pt-onnx-ov/None/az-register-models\\r\\n2023-05-25 07:04:18,974 I [86] azmlinfsrv.print - File: /var/azureml-app/azureml-models/padchest-pt-onnx-ov/None/az-register-models/pc-densenet-densenet-best.bin\\r\\n2023-05-25 07:04:18,974 I [86] azmlinfsrv.print - File: /var/azureml-app/azureml-models/padchest-pt-onnx-ov/None/az-register-models/pc-densenet-densenet-best.onnx\\r\\n2023-05-25 07:04:18,974 I [86] azmlinfsrv.print - File: /var/azureml-app/azureml-models/padchest-pt-onnx-ov/None/az-register-models/pc-densenet-densenet-best.pt\\r\\n2023-05-25 07:04:18,974 I [86] azmlinfsrv.print - File: /var/azureml-app/azureml-models/padchest-pt-onnx-ov/None/az-register-models/pc-densenet-densenet-best.xml\\r\\n2023-05-25 07:04:18,974 E [86] azmlinfsrv - User\\'s init function failed\\r\\n2023-05-25 07:04:18,975 E [86] azmlinfsrv - Encountered Exception Traceback (most recent call last):\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/user_script.py\", line 117, in invoke_init\\r\\n    self._user_init()\\r\\n  File \"/var/azureml-app/4.2.Deploy the model(optimized)_sdk_v2/score_opt_local.py\", line 51, in init\\r\\n    modelx = torch.load(model_path)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/torch/serialization.py\", line 771, in load\\r\\n    with _open_file_like(f, \\'rb\\') as opened_file:\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/torch/serialization.py\", line 270, in _open_file_like\\r\\n    return _open_file(name_or_buffer, mode)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/torch/serialization.py\", line 251, in __init__\\r\\n    super(_open_file, self).__init__(open(name, mode))\\r\\nFileNotFoundError: [Errno 2] No such file or directory: \\'/var/azureml-app/azureml-models/padchest-pt-onnx-ov/1/az-register-models/pc-densenet-densenet-best.pt\\'\\r\\n\\r\\nThe above exception was the direct cause of the following exception:\\r\\n\\r\\nTraceback (most recent call last):\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/aml_blueprint.py\", line 106, in setup\\r\\n    self.user_script.invoke_init()\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/user_script.py\", line 119, in invoke_init\\r\\n    raise UserScriptException(ex) from ex\\r\\nazureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\\r\\n\\r\\n2023-05-25 07:04:18,975 I [86] azmlinfsrv - Model Directory Contents:\\r\\n2023-05-25 07:04:18,975 I [86] azmlinfsrv - None/\\r\\n2023-05-25 07:04:18,987 I [86] azmlinfsrv -     .amlignore\\r\\n2023-05-25 07:04:18,987 I [86] azmlinfsrv -     .amlignore.amltmp\\r\\n2023-05-25 07:04:18,987 I [86] azmlinfsrv -     az-register-models/\\r\\n2023-05-25 07:04:19,001 I [86] azmlinfsrv -         pc-densenet-densenet-best.bin\\r\\n2023-05-25 07:04:19,002 I [86] azmlinfsrv -         pc-densenet-densenet-best.onnx\\r\\n2023-05-25 07:04:19,002 I [86] azmlinfsrv -         pc-densenet-densenet-best.pt\\r\\n2023-05-25 07:04:19,002 I [86] azmlinfsrv -         pc-densenet-densenet-best.xml\\r\\n2023-05-25 07:04:19,002 I [86] azmlinfsrv -     class_names.txt\\r\\n2023-05-25 07:04:19,002 I [86] azmlinfsrv -     pc-densenet-densenet-best.onnx\\r\\n2023-05-25 07:04:19,002 I [86] azmlinfsrv -     pc-densenet-densenet-best.pt\\r\\n2023-05-25 07:04:19,002 I [86] azmlinfsrv -     pc-densenet-densenet-metrics.pkl\\r\\n2023-05-25 07:04:19,002 I [86] gunicorn.error - Worker exiting (pid: 86)\\r\\n2023-05-25 07:04:19,438 I [24] gunicorn.error - Shutting down: Master\\r\\n2023-05-25 07:04:19,438 I [24] gunicorn.error - Reason: Worker failed to boot.\\r\\n2023-05-25T07:04:19,486084449+00:00 - gunicorn/finish 3 0\\r\\n2023-05-25T07:04:19,487602771+00:00 - Exit code 3 is not normal. Killing image.\\r\\nERROR conda.cli.main_run:execute(47): `conda run runsvdir /var/runit` failed. (See above for error)\\r\\n2023-05-25T07:04:19,493888762+00:00 - rsyslog/finish 0 0\\r\\n2023-05-25T07:04:19,495525586+00:00 - Exit code 0 is not normal. Restarting rsyslog.\\r\\n2023-05-25T07:04:19,496559601+00:00 - nginx/finish 0 0\\r\\n2023-05-25T07:04:19,497773819+00:00 - Exit code 0 is not normal. Killing image.\\r\\nrunsvdir: no process found\\r\\n'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.online_deployments.get_logs(\n",
        "    name=\"blue\", endpoint_name=endpoint_name, local=True, lines=500\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'blue': 100}\n",
            "http://localhost:32815/score\n"
          ]
        }
      ],
      "source": [
        "# Get the details for online endpoint\n",
        "endpoint_deployed = ml_client.online_endpoints.get(name=endpoint_name, local=True)\n",
        "\n",
        "# existing traffic details\n",
        "print(endpoint_deployed.traffic)\n",
        "\n",
        "# Get the scoring URI\n",
        "print(endpoint_deployed.scoring_uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output: b'{\"pt_summary\": {\"fwk_version\": \"PyTorch: 1.13.1+cpu\", \"pt_result\": {\"top_labels\": [\"Pneumonia\", \"Infiltration\", \"Effusion\"], \"top_probabilities\": [49.63, 32.22, 3.29]}, \"avg_latency\": 0.04688107744555607, \"fps\": 21.33056777889373}, \"ipex_summary\": {\"fwk_version\": \"IPEX: 1.13.100\", \"ipex_result\": {\"top_labels\": [\"Pneumonia\", \"Infiltration\", \"Effusion\"], \"top_probabilities\": [49.63, 32.22, 3.29]}, \"avg_latency\": 0.03330107722513476, \"fps\": 30.029058616915453}, \"ov_summary\": {\"fwk_version\": \"OpenVINO: 2022.3.0-9052-9752fafe8eb-releases/2022/3\", \"ov_result\": {\"top_labels\": [\"Pneumonia\", \"Infiltration\", \"Effusion\"], \"top_probabilities\": [49.63, 32.22, 3.29]}, \"avg_latency\": 0.021866312714122788, \"fps\": 45.73244758153167}, \"system_info\": {\"lscpu_out\": \"Architecture:                    x86_64\\\\nCPU op-mode(s):                  32-bit, 64-bit\\\\nByte Order:                      Little Endian\\\\nAddress sizes:                   46 bits physical, 48 bits virtual\\\\nCPU(s):                          8\\\\nOn-line CPU(s) list:             0-7\\\\nThread(s) per core:              2\\\\nCore(s) per socket:              4\\\\nSocket(s):                       1\\\\nNUMA node(s):                    1\\\\nVendor ID:                       GenuineIntel\\\\nCPU family:                      6\\\\nModel:                           85\\\\nModel name:                      Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz\\\\nStepping:                        7\\\\nCPU MHz:                         2593.906\\\\nBogoMIPS:                        5187.81\\\\nVirtualization:                  VT-x\\\\nHypervisor vendor:               Microsoft\\\\nVirtualization type:             full\\\\nL1d cache:                       128 KiB\\\\nL1i cache:                       128 KiB\\\\nL2 cache:                        4 MiB\\\\nL3 cache:                        35.8 MiB\\\\nNUMA node0 CPU(s):               0-7\\\\nVulnerability Itlb multihit:     KVM: Mitigation: VMX disabled\\\\nVulnerability L1tf:              Mitigation; PTE Inversion; VMX conditional cache flushes, SMT vulnerable\\\\nVulnerability Mds:               Mitigation; Clear CPU buffers; SMT Host state unknown\\\\nVulnerability Meltdown:          Mitigation; PTI\\\\nVulnerability Mmio stale data:   Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown\\\\nVulnerability Retbleed:          Vulnerable\\\\nVulnerability Spec store bypass: Vulnerable\\\\nVulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization\\\\nVulnerability Spectre v2:        Mitigation; Retpolines, STIBP disabled, RSB filling, PBRSB-eIBRS Not affected\\\\nVulnerability Srbds:             Not affected\\\\nVulnerability Tsx async abort:   Mitigation; Clear CPU buffers; SMT Host state unknown\\\\nFlags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti tpr_shadow vnmi ept vpid fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm avx512f avx512dq rdseed adx smap clflushopt avx512cd avx512bw avx512vl xsaveopt xsavec xsaves md_clear\\\\n\", \"mem_out_gb\": \"              total        used        free      shared  buff/cache   available\\\\nMem:             15           5           0           0           9           9\\\\nSwap:            15           0          15\\\\n\", \"fwk_versions\": {\"PyTorch\": \"1.13.1+cpu\", \"IPEX\": \"1.13.100\", \"OpenVINO\": \"2022.3.0-9052-9752fafe8eb-releases/2022/3\"}, \"os\": \"NAME=\\\\\"Ubuntu\\\\\"\\\\nVERSION=\\\\\"20.04.6 LTS (Focal Fossa)\\\\\"\\\\nID=ubuntu\\\\nID_LIKE=debian\\\\nPRETTY_NAME=\\\\\"Ubuntu 20.04.6 LTS\\\\\"\\\\nVERSION_ID=\\\\\"20.04\\\\\"\\\\nHOME_URL=\\\\\"https://www.ubuntu.com/\\\\\"\\\\nSUPPORT_URL=\\\\\"https://help.ubuntu.com/\\\\\"\\\\nBUG_REPORT_URL=\\\\\"https://bugs.launchpad.net/ubuntu/\\\\\"\\\\nPRIVACY_POLICY_URL=\\\\\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\\\\\"\\\\nVERSION_CODENAME=focal\\\\nUBUNTU_CODENAME=focal\\\\n \\\\nLinux d985cf6e9288 5.15.0-1035-azure #42~20.04.1-Ubuntu SMP Wed Mar 1 19:17:41 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux\\\\n\\\\n/opt/miniconda/envs/inf-conda-env/bin/python\\\\n\"}}'\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "test_file = \"./sample_dicom.dcm\"\n",
        "files = {'image': open(test_file, 'rb').read()}\n",
        "\n",
        "# resp = requests.post(scoring_uri, input_data, headers=headers)\n",
        "scoring_uri = endpoint_deployed.scoring_uri\n",
        "\n",
        "# Send the DICOM as a raw HTTP request and obtain results from endpoint.\n",
        "response = requests.post(scoring_uri, files=files)\n",
        "print(\"output:\", response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch Metrics:\n",
            "\tFramework Version:\t1.13.1+cpu\n",
            "\tTop Labels:\t['Pneumonia', 'Infiltration', 'Effusion']\n",
            "\tTop Probabilities:\t[49.63, 32.22, 3.29]\n",
            "\tAvg Latency:\t0.0469 sec\n",
            "\tFPS:\t21.33\n",
            "\n",
            "IPEX Metrics:\n",
            "\tFramework Version:\t1.13.100\n",
            "\tTop Labels:\t['Pneumonia', 'Infiltration', 'Effusion']\n",
            "\tTop Probabilities:\t[49.63, 32.22, 3.29]\n",
            "\tAvg Latency:\t0.0333 sec\n",
            "\tFPS:\t30.03\n",
            "\n",
            "OpenVINO Metrics:\n",
            "\tFramework Version:\t2022.3.0-9052-9752fafe8eb-releases/2022/3\n",
            "\tTop Labels:\t['Pneumonia', 'Infiltration', 'Effusion']\n",
            "\tTop Probabilities:\t[49.63, 32.22, 3.29]\n",
            "\tAvg Latency:\t0.0219 sec\n",
            "\tFPS:\t45.73\n",
            "\n",
            "Speedup with IPEX: 1.41x\n",
            "\n",
            "Speedup with OpenVINO: 2.14x\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "output_dict = json.loads(response.content)\n",
        "\n",
        "pt_metrics = output_dict['pt_summary']\n",
        "ipex_metrics = output_dict['ipex_summary']\n",
        "ov_metrics = output_dict['ov_summary']\n",
        "\n",
        "print(f\"PyTorch Metrics:\")\n",
        "print(f\"\\tFramework Version:\\t{output_dict['system_info']['fwk_versions']['PyTorch']}\")\n",
        "print(f\"\\tTop Labels:\\t{pt_metrics['pt_result']['top_labels']}\")\n",
        "print(f\"\\tTop Probabilities:\\t{pt_metrics['pt_result']['top_probabilities']}\")\n",
        "print(f\"\\tAvg Latency:\\t{pt_metrics['avg_latency']:.4f} sec\")\n",
        "print(f\"\\tFPS:\\t{pt_metrics['fps']:.2f}\")\n",
        "\n",
        "print(f\"\\nIPEX Metrics:\")\n",
        "print(f\"\\tFramework Version:\\t{output_dict['system_info']['fwk_versions']['IPEX']}\")\n",
        "print(f\"\\tTop Labels:\\t{ipex_metrics['ipex_result']['top_labels']}\")\n",
        "print(f\"\\tTop Probabilities:\\t{ipex_metrics['ipex_result']['top_probabilities']}\")\n",
        "print(f\"\\tAvg Latency:\\t{ipex_metrics['avg_latency']:.4f} sec\")\n",
        "print(f\"\\tFPS:\\t{ipex_metrics['fps']:.2f}\")\n",
        "\n",
        "print(f\"\\nOpenVINO Metrics:\")\n",
        "print(f\"\\tFramework Version:\\t{output_dict['system_info']['fwk_versions']['OpenVINO']}\")\n",
        "print(f\"\\tTop Labels:\\t{ov_metrics['ov_result']['top_labels']}\")\n",
        "print(f\"\\tTop Probabilities:\\t{ov_metrics['ov_result']['top_probabilities']}\")\n",
        "print(f\"\\tAvg Latency:\\t{ov_metrics['avg_latency']:.4f} sec\")\n",
        "print(f\"\\tFPS:\\t{ov_metrics['fps']:.2f}\")\n",
        "\n",
        "# Calculate the FPS speedup with IPEX compared to PyTorch\n",
        "ipex_fps_speedup = ipex_metrics['fps'] / pt_metrics['fps']\n",
        "print(f\"\\nSpeedup with IPEX: {ipex_fps_speedup:.2f}x\")\n",
        "\n",
        "# Calculate the FPS speedup with OpenVINO compared to PyTorch\n",
        "ov_fps_speedup = ov_metrics['fps'] / pt_metrics['fps']\n",
        "print(f\"\\nSpeedup with OpenVINO: {ov_fps_speedup:.2f}x\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "System Info:\n",
            "Architecture:                    x86_64\n",
            "CPU op-mode(s):                  32-bit, 64-bit\n",
            "Byte Order:                      Little Endian\n",
            "Address sizes:                   46 bits physical, 48 bits virtual\n",
            "CPU(s):                          8\n",
            "On-line CPU(s) list:             0-7\n",
            "Thread(s) per core:              2\n",
            "Core(s) per socket:              4\n",
            "Socket(s):                       1\n",
            "NUMA node(s):                    1\n",
            "Vendor ID:                       GenuineIntel\n",
            "CPU family:                      6\n",
            "Model:                           85\n",
            "Model name:                      Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz\n",
            "Stepping:                        7\n",
            "CPU MHz:                         2593.906\n",
            "BogoMIPS:                        5187.81\n",
            "Virtualization:                  VT-x\n",
            "Hypervisor vendor:               Microsoft\n",
            "Virtualization type:             full\n",
            "L1d cache:                       128 KiB\n",
            "L1i cache:                       128 KiB\n",
            "L2 cache:                        4 MiB\n",
            "L3 cache:                        35.8 MiB\n",
            "NUMA node0 CPU(s):               0-7\n",
            "Vulnerability Itlb multihit:     KVM: Mitigation: VMX disabled\n",
            "Vulnerability L1tf:              Mitigation; PTE Inversion; VMX conditional cache flushes, SMT vulnerable\n",
            "Vulnerability Mds:               Mitigation; Clear CPU buffers; SMT Host state unknown\n",
            "Vulnerability Meltdown:          Mitigation; PTI\n",
            "Vulnerability Mmio stale data:   Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown\n",
            "Vulnerability Retbleed:          Vulnerable\n",
            "Vulnerability Spec store bypass: Vulnerable\n",
            "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization\n",
            "Vulnerability Spectre v2:        Mitigation; Retpolines, STIBP disabled, RSB filling, PBRSB-eIBRS Not affected\n",
            "Vulnerability Srbds:             Not affected\n",
            "Vulnerability Tsx async abort:   Mitigation; Clear CPU buffers; SMT Host state unknown\n",
            "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti tpr_shadow vnmi ept vpid fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm avx512f avx512dq rdseed adx smap clflushopt avx512cd avx512bw avx512vl xsaveopt xsavec xsaves md_clear\n",
            "\n",
            "\n",
            "System Memory Info (GB):\n",
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:             15           5           0           0           9           9\n",
            "Swap:            15           0          15\n",
            "\n",
            "\n",
            "System OS:\n",
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"20.04.6 LTS (Focal Fossa)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 20.04.6 LTS\"\n",
            "VERSION_ID=\"20.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=focal\n",
            "UBUNTU_CODENAME=focal\n",
            " \n",
            "Linux d985cf6e9288 5.15.0-1035-azure #42~20.04.1-Ubuntu SMP Wed Mar 1 19:17:41 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux\n",
            "\n",
            "/opt/miniconda/envs/inf-conda-env/bin/python\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Print System info\n",
        "lscpu_out=output_dict['system_info']['lscpu_out'].encode().decode('unicode_escape')\n",
        "print(f\"\\nSystem Info:\\n{lscpu_out}\")\n",
        "\n",
        "mem_out_gb=output_dict['system_info']['mem_out_gb'].encode().decode('unicode_escape')\n",
        "print(f\"\\nSystem Memory Info (GB):\\n{mem_out_gb}\")\n",
        "\n",
        "os_out=output_dict['system_info']['os'].encode().decode('unicode_escape')\n",
        "print(f\"\\nSystem OS:\\n{os_out}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Delete endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "ml_client.online_endpoints.begin_delete(name=endpoint_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
